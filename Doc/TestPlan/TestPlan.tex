\documentclass[12pt, titlepage]{article}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{enumitem}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}
\title{SE 3XA3: Test Plan\\xPycharts}
\author{Team 4, xPy
		\\ Hatim Rehman (rehmah3)
		\\ Louis Bursey (burseylj)
		\\ Sarthak Desai (desaisa3)
}
\date{\today}
\input{../Comments}
\begin{document}
\maketitle
\pagenumbering{roman}
\tableofcontents
\listoftables
\listoffigures
\begin{table}[bp]
\caption{\bf Revision History}
\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Oct. 31, 2016 & 1.0 & Revision 0\\
\bottomrule
\end{tabularx}
\end{table}
\newpage
\pagenumbering{arabic}
\section{General Information}
\subsection{Purpose}
The document will serve as a description of the test cases and methods that will be used to verify that that XPYCharts library for Python functions according to the requirements stated in the SRS documentation. The testing procedures will be a combination of functional, structural, dynamic, manual and automated testing methods that will help detect and locate errors within the implementation of the library. The test cases being used in this document were in design since the start of the project and were built upon progressively through every step of the project up to and including the implementation phase. Finally this document will provide explicit inputs and expected outputs alongside step by step methods on how the testing will be carried out in each scenario. 
\subsection{Scope}
The scope of the test plan includes the data filtering mechanism (checks to see if the data entered is valid to be plotted, if not exceptions are raised) of the XPYCharts library, the axis scaling algorithm (produces a scale that is fitting for all data points entered), the output generated as graphs (this includes the scatter plots and the lines graphs that connect all points of a function). The scope will not cover tkinter that is being used by the library as it is assumed that the package in already tested and verified. 
\subsection{Acronyms, Abbreviations, and Symbols}
	
\begin{table}[hbp]
\caption{\textbf{Table of Abbreviations}} \label{Table}
\begin{tabularx}{\textwidth}{p{3cm}X}
\toprule
\textbf{Abbreviation} & \textbf{Definition} \\
\midrule
Abbreviation1 & Definition1\\
Abbreviation2 & Definition2\\
\bottomrule
\end{tabularx}
\end{table}
\begin{table}[!htbp]
\caption{\textbf{Table of Definitions}} \label{Table}
\begin{tabularx}{\textwidth}{p{3cm}X}
\toprule
\textbf{Term} & \textbf{Definition}\\
\midrule
Term1 & Definition1\\
Term2 & Definition2\\
\bottomrule
\end{tabularx}
\end{table}	
\subsection{Overview of Document}
This is a testing document that is prepared for the XPYCharts library for Python. This document highlights the test strategies and test cases that will be used to verify and validate the functionality of the project as per the requirements stated in the requirements documentation. The document also highlights the tools and software that will be used for the testing. 
\section{Plan}
	
\subsection{Software Description}
XPYCharts is a graphing library that is available to developers in Python. The library allows the developers to generate line graphs and scatter plots by inputting data points or functions using the library API.
\subsection{Test Team}
The test team solely involves the members of the XPYCharts development team that include Sarthak Desai, Hatim Rehman and Louis Bursey.
\subsection{Automated Testing Approach}
The outputs generated by the XPYCharts library include graphs. Although these can be checked by manual testing and automated approach is necessary in order to allow exhaustive testing. However since the output is an image conventional automated testing methods cannot be used. From our research, the team was able to find an image comparison tool that will be used for testing the graphs generated. The automated scripts will take the images generated from the XPYCharts and save them on the local machine, alongside images for the same dataset generated by an external graphing library. Then the image comparison tool will be used in order to determine the difference between the two images. The test will output the ratio of the difference between the two images and whether the two images were concluded to be identical or not. The scripts for the automated testing will also check how long does the library take to generate the graphs as one of the non-functional requirements is speed. For the remaining aspects of the program such as checking the data filtering mechanism and the scaling, automated testing will be done conventionally using unit testing in Python.
\subsection{Testing Tools}
For unit testing the team will be using Python unittest, for external graphing the project will use matplotlib and for image comparison this tool will be used. Testing will also use Pylint to check for code structure and error detection. 
\subsection{Testing Schedule}
The testing schedule of the project is shown by the following
 \href{run:../DevelopmentPlan/GanttChart.gan} {\underline{Gantt Chart}}.
\section{System Test Description}

It is important to note that because of the lack of resources (mainly time), the testing will not be able to cover a wide array of test cases. At times, single positive and negative test cases will be enough to ensure a program works as expected. 	
\subsection{Tests for Functional Requirements}

\subsubsection{Area of Testing 1}		
	\label{sec:3.1.1}
	\paragraph{Requirement \#1: The software shall read data given to it. \\ Requirements \#3: The software will plot all the data points.}

		\begin{enumerate}
			\item{\textbf{Test ID \#1.1\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} Instantiate Graph(6) object with 6 markings on each quadrant.\\
			\textbf{Input:} The list object: [ (1, 1),  (2, 2), (3, 3), (4, 4) ]\\
			\textbf{Output:} A window depicting a graph with plotted points at (1, 1), (2, 2), (3, 3), and (4, 4). \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object.
					\item The list object will be passed into the plotting method in the API.
					\item The program will run to completion.
					\item The user will manually verify the points plotted correspond to the ones entered.
				\end{itemize}
					
			\item{\textbf{Test ID \#1.2\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} None Object.\\
			\textbf{Input:} Instantiate Graph(6, data = [ (1, 1),  (2, 2), (3, 3), (4, 4) ] )\\
			\textbf{Output:} A window depicting a graph with plotted points at (1, 1), (2, 2), (3, 3), and (4, 4). \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object with data immediately.
					\item The program will run to completion.
					\item The user will manually verify the points plotted correspond to the ones entered.
				\end{itemize}
				
			\item{\textbf{Test ID \#1.3\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} Instantiate Graph(6) object with 6 markings on each quadrant.\\
			\textbf{Input:} The list object: [	].\\
			\textbf{Output:} A window depicting a graph with no plotted points.\\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object.
					\item The list object will be passed into the plotting method in the API.
					\item The program will run to completion.
					\item The user will manually verify that no points were plotted.
				\end{itemize}				

			\item{\textbf{Test ID \#1.4\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} None Object.\\
			\textbf{Input:} Instantiate Graph(6, data = [  ] )\\
			\textbf{Output:} A window depicting a graph with no plotted points.\\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object with data immediately.
					\item The program will run to completion.
					\item The user will manually verify that no points were plotted.
				\end{itemize}	
	\end{enumerate}
After this point, it should be also verified that instantiating a Graph object with data versus instantiating a Graph object and then setting the data should have no difference in the output. Therefore, after this point all test cases will (decided arbitrarily) initialize a Graph object and then set the data if the situation arises. This will be done purely to save time, which is a limitation. 

\subsubsection{Area of Testing 2}		
	\paragraph{Requirement \#2: The software will raise an exception if the data format cannot be plotted, and stop the program.}
		\begin{enumerate}
			\item{\textbf{Test ID \#2.1\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} A testing script that imports the method that validates data. \\
			\textbf{Input:} The list object: [ (1, 1),  (2, 2), (3, 3), (4, 4) ]\\
			\textbf{Output:}  A safe end to the execution (i.e, no exception raised). \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will call the method with the list object.
					\item The user will verify the method completed execution without raising an exception.
				\end{itemize}
					
			\item{\textbf{Test ID \#2.2\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} A testing script that imports the method that validates data.\\
			\textbf{Input:} The list object: [ (1, 1),  (2, 2), (3, 3), ( 4 ) ]\\
			\textbf{Output:} The program raised an exception.\\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will call the method with the list object.
					\item The user will verify the method raised an exception.
				\end{itemize}
									
			\item{\textbf{Test ID \#2.3\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} Instantiate Graph(6) object with 6 markings on each quadrant..\\
			\textbf{Input:} Instantiate Graph(6, data = [ (1, 1),  (2, 2), (3, 3), ( 4 ) ] )\\
			\textbf{Output:} The list object: [ (1, 1),  (2, 2), (3, 3), ( 4 ) ] \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object.
					\item The list object will be passed into the plotting method in the API.
					\item The user will manually verify an exception was raised.
				\end{itemize}				

	\end{enumerate}
2.1 and 2.2 directly test the method that is in charge of raising the exception. 2.3 tests whether it is used correctly in the library. We do not need to again test the positive scenario of 2.3 as this will have been tested with Area of Testing 1. 

\subsubsection{Area of Testing 3}		
	\paragraph{Requirement \#3: The software will construct a coordinate system that will fit all the data points.}
		\begin{enumerate}
			\item{\textbf{Test ID \#3.1\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} Instantiate Graph(6) object with 6 markings on each quadrant. \\
			\textbf{Input:} The list object: [ (1, 1),  (2, 2), (3, 3), ( 17, 77) ]\\
			\textbf{Output:}  A window depicting a graph with max x axis value to be 17 and -17, and y axis to be 77 and -77. \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object.
					\item The list object will be passed into the plotting method in the API.
					\item The program will run to completion.
					\item The user will manually verify the axes are appropriate.								
				\end{itemize}
					
			\item{\textbf{Test ID \#3.2\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:}  Instantiate Graph(6) object with 6 markings on each quadrant.\\
			\textbf{Input:} The list object: [ (1, 1),  (2, 2), (3, 3), ( -17, -77) ]\\
			\textbf{Output:} A window depicting a graph with max x axis value to be 17 and -17, and y axis to be 77 and -77. \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object.
					\item The list object will be passed into the plotting method in the API.
					\item The program will run to completion.
					\item The user will manually verify the axes are appropriate.
				\end{itemize}							
	\end{enumerate}

\subsubsection{Area of Testing 4}		
	\paragraph{Requirement \#4: The software will connect a line that passes through all the data points if the data points are a function of x.\\\\}
	
	This functionality is composed of three stages that were required to complete it: 
	\begin{itemize}[label={ }]
		\item I. The ability to plot points. 
		\item	II. The ability to graph functions. 
	\end{itemize}	 
With the completion of the above 2, and through a method that determines a polynomial (which is a function) that passes through all the data points, we come to the third stage, which is the essence of this functionality: 
	\begin{itemize}[label={ }]
		\item III. A function that passes through all the data points.
		\end{itemize}
		The first stage is assumed to have been tested in Area of Testing 1, and will not be repeated here. Furthermore, because Stage II is an intermediary stage and not an official requirement (at least, not yet), it will be given one test case here, to save time.  
		\begin{enumerate}
			\item{\textbf{Test ID \#4.1\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} An instantiated Graph object. \\
			\textbf{Input:} The default math.sin() function in python.\\
			\textbf{Output:}  A window depicting the sin() graph.\\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object.
					\item The user will call the plot function method in the API with [Math.]sin() as the parameter.
					\item The program will run to completion.
					\item The user will manually verify that the program plotted the function correctly.							
				\end{itemize}
					
			\item{\textbf{Test ID \#4.2\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} An instantiated Graph object.\\
			\textbf{Input:} The list object: [ (1, 1),  (2, 2), (3, 3), (4, 4) ]\\
			\textbf{Output:} A window depicting a graph with the points plotted, and a line is connecting all points. \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object.
					\item The user will call the appropriate method in the API with the data set.
					\item The program will run to completion.
					\item The user will manually verify that the program plotted the points, and a line is connecting all points.
				\end{itemize}							
				
			\item{\textbf{Test ID \#4.3\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:}  An instantiated Graph object.\\
			\textbf{Input:} The list object: [ (1, 1),  (2, 2), (3, 3), (3, 4) ]\\
			\textbf{Output:} An exception will be raised. \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph object.
					\item The user will call the appropriate method in the API with the data set.
					\item The program will run to completion.
					\item The user will manually verify that an exception was raised.
				\end{itemize}
	\end{enumerate}
	
\subsubsection{Area of Testing 5}		
	\paragraph{Testing of source code.}
		\begin{enumerate}
			\item{\textbf{Test ID \#5.1\\}}
			\textbf{Type:} Functional, Static, Automated\
			\textbf{Initial State:} Completed source code. \\
			\textbf{Input:} Source code.\\
			\textbf{Output:} Review of source code.\\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item Pylint ( a python static testing framework) will be used to analyze the source code and determine if there are syntax errors, faulty naming conventions, unused variables, poor quality etc. This testing will be automated.							
				\end{itemize}
		\end{enumerate}
		
\subsubsection{Area of Testing 6}		
	\paragraph{Verifying correctness of output using automated testing.\\\\}
	The challenges in this form of automated testing lie because of the following tasks:
	\begin{itemize}[label={--}]
		\item There needs to be a comparison image that is also generated in an automated fashion. 
		\item	A comparison tool needs to exist that can compare 2 images and determine the difference on some scale.
		\item	The difference scale needs to be normalized to account for static differences that are always present, such as in the way the axes are draw (line thickness for example), the size of the points, the spacing between one point to the next, etc. 
	\end{itemize}	
		\begin{enumerate}
			\item{\textbf{Test ID \#6.1\\}}
			\textbf{Type:} Functional, Dynamic, Automated\
			\textbf{Initial State:} Completed source code. \\
			\textbf{Input:} An image from xPycharts, and a comparison image generated using the same dataset.?Input: The 2 images.\\
			\textbf{Output:}  A numerical value denoting the difference between these two images, and a pass/fail indicator.\\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item Using a python library such as PIL, an image of a graph generated by xPycharts will be saved.
					\item Using an external graphing library (matplotlib), a comparison image will be created.
					\item The script will then proceed to use these 2 images in the comparison tool denoted \href{http://www.pyimagesearch.com/2014/09/15/python-compare-two-images/}{here}.
					\item The program will output a value that will then be normalized by a ratio determined prior.
					\item The program will display the value, and indicate whether it met the threshold for a pass, or failed.							
				\end{itemize}
		\end{enumerate}		
	
	
\subsection{Tests for Nonfunctional Requirements}

Note: see \hyperref[sec:3.1.1]{3.1.1}.
		
\subsubsection{Look and feel}
\begin{enumerate}
\item{\textbf{Test ID \#1\\}}
Type: Structural, Dynamic, Manual
					
Initial State:  Program is ready to produce one of each graph with random data.
					
Input/Condition: Program generates one of each type of graph, with random data inputted
					
Output/Result:  70\% of users say that the graph is ``Visually appealing'' rather than ``Visually unappealing.''
					
How test will be performed: Each user in the test group will be presented with a graph produced from random data. They will rate it as ``visually appealing'' or ``visually unappealing.'' At least 70\% of users must rate it as visually appealing for the test to be passed.
					
\end{enumerate}

\subsubsection{Usability}
\begin{enumerate}
\item{\textbf{Test ID \#2,3,4,5\\}}
Type: Structural, Dynamic, Manual
					
Initial State:  Library is available on computer, IDLE is open, a dataset is downloaded on computer. User group has some knowledge of Python.
					
Input/Condition: Users asked to create one of each graph without assistance
					
Output/Result: 80\% of users are able to produce each graph without assistance. They do not have issue with the linguistic content of the documentation. They produce these graphs in under twenty minutes.
					
How test will be performed: The test group will be given a computer with IDLE open, and a directory on their desktop containing the documentation for this project and sample datasets. They will be asked to produce one of each graph available in this library and will not be given any assistance by the testers. They will be timed. When error messages are created, the user when surveyed will report 80\% of the time that they could understand what the error was.
		
\item{\textbf{Test ID \#5.1\\}}
Type: Structural, Dynamic, Manual
					
Initial State:    Library is available on computer, IDLE is open, a dataset and a series of programs that incorrectly implement the library are downloaded on computer. User group has been acquainted with the library.
					
Input/Condition: Users asked to use library in ways that throw each error message.
					
Output/Result: Each error message is understood by users 80\% of the time
					
How test will be performed: Users will be asked to run programs that incorrectly implement the library. They will be asked to identify the error in implementation based on the error message. The correctness of their answers will be recorded.

 \end{enumerate} 
 
 \subsubsection{Performance}
\begin{enumerate}
\item{\textbf{Test ID \#6,9,10 \\}}
Type: Structural, Dynamic, Automatic
					
Initial State:    Library is available on computer, minimal other programs are open
					
Input/Condition: Script is executed with random datasets, averaging 500 points in a set
					
Output/Result: Results written to text file. Graphs never take more than 20 seconds to produce, and never stall out the program
					
How test will be performed: A script will repeatedly make a random data set, and time how long it takes to make each graph based on that data set. It will time the generation of the graphs and record this in a text file. After executing many times it will confirm that no graph took more than 20 seconds to produce, and that it did not stall out during execution.

 \end{enumerate} 
 
  \subsubsection{Performance}
\begin{enumerate}
\item{\textbf{Test ID \#6,9,10 \\}}
Type: Structural, Dynamic, Automatic
					
Initial State:    Library is available on computer, minimal other programs are open. Automatic testing script is on computer.
					
Input/Condition: Script is executed with random datasets, averaging 500 points in a set
					
Output/Result: Results written to text file. Graphs never take more than 20 seconds to produce, and never stall out the program
					
How test will be performed: A script will repeatedly make a random data set, and time how long it takes to make each graph based on that data set. It will time the generation of the graphs and record this in a text file. After executing many times it will confirm that no graph took more than 20 seconds to produce, and that it did not stall out during execution.

 \end{enumerate} 
 
  \subsubsection{Operational and Environment}
\begin{enumerate}
\item{\textbf{Test ID \#11,12,13,15 \\}}
Type: Structural, Dynamic, Manual
					
Initial State:    Test uses Mac, Windows, Linux computers. Python is installed on computer, program that generates each graph with random dataset is on USB stick with the library (stored as zip file)
					
Input/Condition: Program is executed on computers.
					
Output/Result: All graphs are produced without error.
					
How test will be performed: A USB key with a test program will be inserted into computers running Windows 10, Mac OS 10.9+, and the latest Ubuntu LTS. The program will run successfully.

\item{\textbf{Test ID \#11 \\}}
Type: Structural, Dynamic, Manual
					
Initial State:    Library is available on Mac, Windows, Linux computer. Python is installed on computer, program that generates each graph with random dataset is on USB stick
					
Input/Condition: Program is executed on computers.
					
Output/Result: All graphs are produced without error.
					
How test will be performed: A USB key with a test program will be inserted into computers running Windows 10, Mac OS 10.9+, and the latest Ubuntu LTS. The program will run successfully.

 \end{enumerate} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55
		
Same as described in \hyperref[sec:3.1.1]{3.1.1}.

\section{Comparison to Existing Implementation}	
Edge cases will be tested in this section to ensure the program responds appropriately (determined by existing implementation) in non typical conditions. \\ \\
Once again, it is important to note that because of limited resources, not every case will be tested and at times, a single test case would be sufficient in determining behaviour.	

\subsubsection{Area of Testing 1}		
	\paragraph{Negative and Positive infinities as (x, y).}
		\begin{enumerate}
			\item{\textbf{Test ID \#1.1\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} Instantiate Graph(6) object with 6 markings on each quadrant. Instantiate axisChart object (jCharts).\\	
			\textbf{Input:} The list [( NEGATIVE\_INFINITY, NEGATIVE\_INFINITY),  (POSITIVE\_INFINITY, POSITIVE\_INFINITY) ]\\
			\textbf{Output:}  Uncaught exception in xPycharts, caught exception in jCharts.\\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph objects from both libraries. 
					\item The list object will be passed into the plotting method of the APIs.
					\item The user will manually verify the behaviors of the 2 libraries.
				\end{itemize}					
	\end{enumerate}

\subsubsection{Area of Testing 2}		
	\paragraph{None object as input.}
		\begin{enumerate}
			\item{\textbf{Test ID \#2.1\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} Instantiate Graph(6) object with 6 markings on each quadrant. Instantiate axisChart object (jCharts).\\	
			\textbf{Input:} The list [ ]\\
			\textbf{Output:}  Empty graphs in both xPycharts and jCharts.\\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph objects from both libraries. 
					\item The list object will be passed into the plotting method of the APIs.
					\item The user will manually verify the behaviours of the 2 libraries.
				\end{itemize}					
	\end{enumerate}
	
\subsubsection{Area of Testing 3}
Some (x, y) repeated n times where n is a very large number. 
This area of testing covers the program's speed and efficiency (i.e a non functional requirement).
An efficient library would remove duplicates from the input and would complete this task in ~O(k) time, where k is the time it takes to remove or ignore the duplicates from the input. In contrast, a non efficient system would take ~O(n) time.		
		\begin{enumerate}
			\item{\textbf{Test ID \#3.1\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} Instantiate Graph(6) object with 6 markings on each quadrant. Instantiate axisChart object (jCharts).\\	
			\textbf{Input:} The list [ (1, 1), ? , (1, 1) ] with n spaces in between. \\
			\textbf{Output:}   xPycharts would take a considerably long time. jCharts returns caught exception. \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph objects from both libraries. 
					\item The list object will be passed into the plotting method of the APIs.
					\item The user will manually verify the behaviours of the 2 libraries.
				\end{itemize}					
	\end{enumerate}
\subsubsection{Area of Testing 4}
	\paragraph{Some (x, y, z) coordinates in input.}
		\begin{enumerate}
			\item{\textbf{Test ID \#4.1\\}}
			\textbf{Type:} Functional, Dynamic, Manual\\
			\textbf{Initial State:} Instantiate Graph(6) object with 6 markings on each quadrant. Instantiate axisChart object (jCharts).\\	
			\textbf{Input:} The list [ (1, 1, 1), (2, 2), (3, 3) ] \\
			\textbf{Output:}    xPycharts would plot (1, 1), (2, 2), and (3, 3). jCharts returns caught exception.  \\
			\textbf{How test will be performed:}
				\begin{itemize}[label={--}]
					\item The user will instantiate the graph objects from both libraries. 
					\item The list object will be passed into the plotting method of the APIs.
					\item The user will manually verify the behaviours of the 2 libraries.
				\end{itemize}					
	\end{enumerate}

				
\section{Unit Testing Plan}
Unit testing will be done with unittest, the Python version of JUnit. Unit tests should be written as units are written.
\subsection{Unit testing of internal functions}
Unit testing for internal functions can be done on methods that return values. We will unit test with inputs that have clear expected outputs and with inputs that generate errors. We will aim for a high degree of code coverage with these unit tests, although the importance of graphics in this project means that there will be some functions that cannot be easily unit tested automatically. We will aim for 70\% coverage, although as the project progresses we will revise this goal if it becomes apparent that it is not realistic. Stubs and drivers should not be needed for this project.
		
\subsection{Unit testing of output files}	
The method described in functional test \#6.1 can be employed to unit test output files. Using python scripts and image comparison, we can unit test output files from specific units. This will require the tools described in functional test \#6.1.

\bibliographystyle{plainnat}
\bibliography{SRS}
\newpage
\section{Appendix}
This is where you can place additional information.
\subsection{Symbolic Parameters}
The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.
\subsection{Usability Survey Questions?}
This is a section that would be appropriate for some teams.
\end{document}